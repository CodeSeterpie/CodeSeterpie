# -*- coding: utf-8 -*-
"""notebook05.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ibyxYyFrrHtrXo_7wFpsGgJNRhbbfkv9
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from keras import metrics
from keras.models import Sequential
from keras.layers import Dense,  LSTM
from sklearn.preprocessing import MinMaxScaler
from datetime import date, timedelta

# inputフォルダに格納されているファイルの一覧を出力
BASE_PATH = '/content/drive/My Drive/CodeSeterpie/PredictFutureSales/input'

for dirname, _, filenames in os.walk(BASE_PATH):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# データファイルの読み込み
item_categories = pd.read_csv(BASE_PATH + '/item_categories.csv')
items = pd.read_csv(BASE_PATH + '/items.csv')
sales_train = pd.read_csv(BASE_PATH + '/sales_train.csv')
sample_submission = pd.read_csv(BASE_PATH + '/sample_submission.csv')
shops = pd.read_csv(BASE_PATH + '/shops.csv')
test = pd.read_csv(BASE_PATH + '/test.csv')

test.head()

# 予測対象のファイル(test)をベースに、
# 2013年1月(date_block_num=0)〜2015年11月(date_block_num=35)まで増幅する
test_201301to201511 = test.copy()

test_201301to201511['crossjoin_key'] = 1

data_fill = pd.DataFrame({'crossjoin_key' : 1,
                          'date_block_num' : range(0, 35)})

test_201301to201511 = pd.merge(test_201301to201511, 
                               data_fill, 
                               how='outer', 
                               on='crossjoin_key')

test_201301to201511 = test_201301to201511.drop(['crossjoin_key'], axis=1)

test_201301to201511.head()

# salse_trainからshop_id、item_id別に月ごとの売上数を算出する
# Todo:追加の特徴量として、item_priceの月ごとの平均値等を算出してもいいかもしれない。
sales_train_groupby = sales_train.drop(['date', 'item_price'], axis=1)
sales_train_groupby = sales_train_groupby.groupby(['date_block_num', 
                                                   'shop_id', 
                                                   'item_id']).sum().reset_index()

sales_train_groupby.head()

# test_201301to201511に各月の売上数を結合。
test_201301to201511 = pd.merge(test_201301to201511, 
                               sales_train_groupby, 
                               how='left', 
                               left_on=['shop_id', 'item_id', 'date_block_num'], 
                               right_on=['shop_id', 'item_id', 'date_block_num'])
 
# 全ての月に売上数のデータがあるわけではないので、データがない箇所は0.0で埋める
test_201301to201511 = test_201301to201511.fillna({'item_cnt_day' : 0.0})

# データをソートし直す
test_201301to201511 = test_201301to201511.sort_values(['date_block_num', 'ID'])
test_201301to201511 = test_201301to201511.reset_index(drop=True)

test_201301to201511.head()

len_one_month = len(test)
len_201301to201511 = len(test_201301to201511)

print(f'len_one_month: {len_one_month :.0f}')
print(f'len_201301to201511: {len_201301to201511 :.0f}')

item_cnt_day = test_201301to201511.iloc[:, 4]  # item_cnt_day列のみ抽出する。
item_cnt_day = np.array(item_cnt_day)                     # numpy配列に変換する。
item_cnt_day = item_cnt_day.reshape(-1, 1)                # 行列に変換する。（配列の要素数行×1列）

date_block_num = test_201301to201511.iloc[:, 3] # date_block_num列のみ抽出する。
date_block_num = np.array(date_block_num)       # numpy配列に変換する。
date_block_num = date_block_num.reshape(-1, 1)  # 行列に変換する。（配列の要素数行×1列）

X1 = item_cnt_day[0*len_one_month:len_201301to201511-5*len_one_month, :]     # 予測対象の5ヶ月前のデータ
X2 = item_cnt_day[1*len_one_month:len_201301to201511-4*len_one_month, :]     # 予測対象の4ヶ月前のデータ
X3 = item_cnt_day[2*len_one_month:len_201301to201511-3*len_one_month, :]     # 予測対象の3ヶ月前のデータ
X4 = item_cnt_day[3*len_one_month:len_201301to201511-2*len_one_month, :]     # 予測対象の2ヶ月前のデータ
X5 = item_cnt_day[4*len_one_month:len_201301to201511-1*len_one_month, :]     # 予測対象の前月データ
Y  = item_cnt_day[5*len_one_month:len_201301to201511, :]                 # 予測対象月のデータ
date_block_num = date_block_num[5*len_one_month:len_201301to201511, :]  # 予測対象月のデータ

# numpy配列を結合する。
X = np.concatenate([date_block_num, X1, X2, X3, X4, X5], axis=1)  

print(Y)
print(X)

scaler_X = MinMaxScaler()  # データを0～1の範囲にスケールするための関数。
scaler_X.fit(X)  # スケーリングに使用する最小／最大値を計算する。
X = scaler_X.transform(X)  # Xをを0～1の範囲にスケーリングする。
X = np.reshape(X, (X.shape[0], 1, X.shape[1]))  # 3次元配列に変換する。

scaler_Y = MinMaxScaler()  # データを0～1の範囲にスケールするための関数。
scaler_Y.fit(Y)  # スケーリングに使用する最小／最大値を計算する。
Y = scaler_Y.transform(Y)  # Yをを0～1の範囲にスケーリングする。

print(X)
print(Y)

len_X = len(X)

print(f'len_X: {len_X:.0f}')
print(f'len_one_month: {len_one_month:.0f}')
print(f'len_201301to201511: {len_201301to201511:.0f}')

# train, validation, testデータを定義
tr_X = X[                     :len_X-len_one_month*2, :, :]
va_X = X[len_X-len_one_month*2:len_X-len_one_month*1, :, :]
te_X = X[len_X-len_one_month*1:                     , :, :]

tr_Y = Y[                     :len_X-len_one_month*2, :]
va_Y = Y[len_X-len_one_month*2:len_X-len_one_month*1, :]
te_Y = Y[len_X-len_one_month*1:                     , :]

print(len(tr_X))
print(len(va_X))
print(len(te_X))

# データ予測用のモデルを作成
model = Sequential()
model.add(LSTM(10, 
               activation = 'tanh', 
               input_shape = (1,6), 
               recurrent_activation= 'hard_sigmoid'))
model.add(Dense(1))

model.compile(loss= 'mean_squared_error', 
              optimizer = 'rmsprop', 
              metrics=[metrics.mae])

model.fit(tr_X, 
          tr_Y, 
          epochs=1, 
          verbose=2)

te_pred = model.predict(te_X)
va_pred = model.predict(va_X)

print(va_Y)
print(va_pred)

# オリジナルのスケールに戻す。
inv_tr_Y = scaler_Y.inverse_transform(tr_Y)
inv_tr_Y = pd.DataFrame(inv_tr_Y)

inv_va_Y = scaler_Y.inverse_transform(va_Y)
inv_va_Y = pd.DataFrame(inv_va_Y)

inv_te_pred = scaler_Y.inverse_transform(te_pred)
inv_te_pred = pd.DataFrame(inv_te_pred)

inv_va_pred = scaler_Y.inverse_transform(va_pred)
inv_va_pred = pd.DataFrame(inv_va_pred)

print(inv_va_Y)
print(inv_va_pred)

# 予測値と真の値をプロット
plt.figure(figsize=(15,10), facecolor='white')
plt.plot(inv_va_Y, label = 'true value')
plt.plot(inv_va_pred, label = 'prediction')
plt.legend(loc='best')
plt.show()

# Kaggle提出用のcsvファイルを出力する
sub = inv_te_pred.copy()
sub.columns = ['item_cnt_month']
sub['ID'] = sub.index
sub = sub.loc[:, ['ID', 'item_cnt_month']]

print(sub)

sub.to_csv('submisson.csv', index=False)