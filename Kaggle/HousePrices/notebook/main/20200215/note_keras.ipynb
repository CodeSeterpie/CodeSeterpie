{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputファイルを表示: 2020-02-16 09:28:25.208004\n",
      "/kaggle/input/test.csv\n",
      "/kaggle/input/data_description.txt\n",
      "/kaggle/input/train.csv\n",
      "/kaggle/input/.ipynb_checkpoints/train-checkpoint.csv\n",
      "/kaggle/input/.ipynb_checkpoints/test-checkpoint.csv\n",
      "/kaggle/input/.ipynb_checkpoints/data_description-checkpoint.txt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import itertools\n",
    "\n",
    "# ログ出力用の関数\n",
    "def printTime(tag):\n",
    "    print(tag + ':', datetime.datetime.now())\n",
    "\n",
    "\n",
    "printTime('Inputファイルを表示')\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 学習データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/test.csv')\n",
    "\n",
    "# 学習データを特徴量と目的変数に分ける\n",
    "train_x = train.drop(['SalePrice'], axis=1)\n",
    "train_y = train['SalePrice']\n",
    "\n",
    "# テストデータは特徴量のみなので、そのままでよい\n",
    "test_x = test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 特徴量作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解析対象とする数値列を設定\n",
    "targets_num = ['1stFlrSF',\n",
    "               '2ndFlrSF'\n",
    "               'BsmtFinSF1',\n",
    "               'Fireplaces',\n",
    "               'FullBath',\n",
    "               'GarageArea',\n",
    "               'GarageCars',\n",
    "               'GarageYrBlt',\n",
    "               'GrLivArea',\n",
    "               'MasVnrArea',\n",
    "               'OverallQual',\n",
    "               'OverallCond',\n",
    "               'TotalBsmtSF',\n",
    "               'TotRmsAbvGrd',\n",
    "               'YearBuilt',\n",
    "               'YearRemodAdd']\n",
    "\n",
    "# 解析対象とするカテゴリ列を設定\n",
    "targets_category = [\n",
    "                    'MSSubClass',\n",
    "                    'MSZoning',\n",
    "                    'Street',\n",
    "                    'Alley',\n",
    "                    'LotShape',\n",
    "                    'LandContour',\n",
    "                    'Utilities',\n",
    "                    'LotConfig',\n",
    "                    'LandSlope',\n",
    "                    'Neighborhood',\n",
    "                    'Condition1',\n",
    "                    'Condition2',\n",
    "                    'BldgType',\n",
    "                    'HouseStyle',\n",
    "                    'RoofStyle',\n",
    "                    'RoofMatl',\n",
    "                    'Exterior1st',\n",
    "                    'Exterior2nd',\n",
    "                    'MasVnrType',\n",
    "                    'ExterQual',\n",
    "                    'ExterCond',\n",
    "                    'Foundation',\n",
    "                    'BsmtQual',\n",
    "                    'BsmtCond',\n",
    "                    'BsmtExposure',\n",
    "                    'BsmtFinType1',\n",
    "                    'BsmtFinType2',\n",
    "                    'Heating',\n",
    "                    'HeatingQC',\n",
    "                    'CentralAir',\n",
    "                    'Electrical',\n",
    "                    'KitchenQual',\n",
    "                    'Functional',\n",
    "                    'FireplaceQu',\n",
    "                    'GarageType',\n",
    "                    'GarageFinish',\n",
    "                    'GarageQual',\n",
    "                    'GarageCond',\n",
    "                    'PavedDrive',\n",
    "                    'PoolQC',\n",
    "                    'Fence',\n",
    "                    'MiscFeature',\n",
    "                    'SaleType',\n",
    "                    'SaleCondition']\n",
    "\n",
    "# 解析対象とする数値列とカテゴリ列の列名を連結\n",
    "targets = targets_num\n",
    "targets.extend(targets_category)\n",
    "\n",
    "# 解析対象列のみを抽出\n",
    "train_x = train_x.reindex(columns=targets)\n",
    "test_x = test_x.reindex(columns=targets)\n",
    "\n",
    "# Dataframeの列の型がobjectのままだとLabelEncoderでエラーするため、strに変換\n",
    "# ※変換処理後にinfo()で型を確認しても、objectと表示されるが内部的にはstrに変換されている。\n",
    "train_x[targets_category] = train_x[targets_category].astype(str)\n",
    "test_x[targets_category] = test_x[targets_category].astype(str)\n",
    "\n",
    "# ラベルエンコーディング用に学習データとテストデータをunion\n",
    "lavel_x = train_x.append(test_x, ignore_index=True)\n",
    "\n",
    "# カテゴリ変数をlabel encodingする\n",
    "for c in targets_category:\n",
    "    # 学習データとテストデータに基づいてラベルを設定\n",
    "    le = LabelEncoder()\n",
    "    le.fit(lavel_x[c])\n",
    "    train_x[c] = le.transform(train_x[c])\n",
    "    test_x[c] = le.transform(test_x[c])\n",
    "\n",
    "\n",
    "# 数値変数のnanを0に変換する\n",
    "for c in targets_num:\n",
    "    train_x[c] = train_x[c].fillna(0)\n",
    "    test_x[c] = test_x[c].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### モデル作成とバリデーション\n",
    "XGBoostを使用してモデルを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "モデルの作成開始: 2020-02-16 09:28:25.531481\n",
      "Train on 1095 samples, validate on 365 samples\n",
      "Epoch 1/100\n",
      "1095/1095 [==============================] - 1s 634us/sample - loss: 39288421461.0995 - val_loss: 38263651611.3534\n",
      "Epoch 2/100\n",
      "1095/1095 [==============================] - 0s 117us/sample - loss: 39253318886.9845 - val_loss: 38194296220.4055\n",
      "Epoch 3/100\n",
      "1095/1095 [==============================] - 0s 115us/sample - loss: 39128229508.3251 - val_loss: 37980555415.4959\n",
      "Epoch 4/100\n",
      "1095/1095 [==============================] - 0s 102us/sample - loss: 38763185882.3598 - val_loss: 37434800335.6055\n",
      "Epoch 5/100\n",
      "1095/1095 [==============================] - 0s 97us/sample - loss: 37925651228.7562 - val_loss: 36232035757.2384\n",
      "Epoch 6/100\n",
      "1095/1095 [==============================] - 0s 99us/sample - loss: 36045572412.0840 - val_loss: 33904299830.0055\n",
      "Epoch 7/100\n",
      "1095/1095 [==============================] - 0s 96us/sample - loss: 32804838322.3817 - val_loss: 29943113178.1260\n",
      "Epoch 8/100\n",
      "1095/1095 [==============================] - 0s 115us/sample - loss: 27624284236.6831 - val_loss: 24118663010.8932\n",
      "Epoch 9/100\n",
      "1095/1095 [==============================] - 0s 104us/sample - loss: 20598663742.1881 - val_loss: 17054022013.5452\n",
      "Epoch 10/100\n",
      "1095/1095 [==============================] - 0s 102us/sample - loss: 13027256104.9132 - val_loss: 11044075851.0466\n",
      "Epoch 11/100\n",
      "1095/1095 [==============================] - 0s 101us/sample - loss: 8118048833.9288 - val_loss: 8575894666.8712\n",
      "Epoch 12/100\n",
      "1095/1095 [==============================] - 0s 102us/sample - loss: 6860267736.9571 - val_loss: 7712201807.9562\n",
      "Epoch 13/100\n",
      "1095/1095 [==============================] - 0s 97us/sample - loss: 5901942257.5050 - val_loss: 6548180279.4082\n",
      "Epoch 14/100\n",
      "1095/1095 [==============================] - 0s 102us/sample - loss: 4864412351.2402 - val_loss: 5798751011.7699\n",
      "Epoch 15/100\n",
      "1095/1095 [==============================] - 0s 103us/sample - loss: 4305346575.6639 - val_loss: 5248272027.7041\n",
      "Epoch 16/100\n",
      "1095/1095 [==============================] - 0s 104us/sample - loss: 3866364838.9260 - val_loss: 4754558956.3616\n",
      "Epoch 17/100\n",
      "1095/1095 [==============================] - 0s 104us/sample - loss: 3486325875.9598 - val_loss: 4372238245.5233\n",
      "Epoch 18/100\n",
      "1095/1095 [==============================] - 0s 124us/sample - loss: 3203065066.7251 - val_loss: 4044880271.7808\n",
      "Epoch 19/100\n",
      "1095/1095 [==============================] - 0s 111us/sample - loss: 2968259988.9242 - val_loss: 3758166105.0740\n",
      "Epoch 20/100\n",
      "1095/1095 [==============================] - 0s 108us/sample - loss: 2748686787.4484 - val_loss: 3518838650.7397\n",
      "Epoch 21/100\n",
      "1095/1095 [==============================] - 0s 102us/sample - loss: 2576269964.3909 - val_loss: 3309936980.1644\n",
      "Epoch 22/100\n",
      "1095/1095 [==============================] - 0s 94us/sample - loss: 2435601994.8128 - val_loss: 3125301419.1342\n",
      "Epoch 23/100\n",
      "1095/1095 [==============================] - 0s 114us/sample - loss: 2340512777.3516 - val_loss: 2964882307.1562\n",
      "Epoch 24/100\n",
      "1095/1095 [==============================] - 0s 101us/sample - loss: 2203676898.8932 - val_loss: 2814865808.4822\n",
      "Epoch 25/100\n",
      "1095/1095 [==============================] - 0s 100us/sample - loss: 2101530821.3187 - val_loss: 2692426298.9151\n",
      "Epoch 26/100\n",
      "1095/1095 [==============================] - 0s 97us/sample - loss: 2022826423.1744 - val_loss: 2583944117.6548\n",
      "Epoch 27/100\n",
      "1095/1095 [==============================] - 0s 104us/sample - loss: 1942759060.4566 - val_loss: 2486843267.1562\n",
      "Epoch 28/100\n",
      "1095/1095 [==============================] - 0s 100us/sample - loss: 1877811646.5388 - val_loss: 2403508414.4219\n",
      "Epoch 29/100\n",
      "1095/1095 [==============================] - 0s 101us/sample - loss: 1818412078.0566 - val_loss: 2328401929.1178\n",
      "Epoch 30/100\n",
      "1095/1095 [==============================] - 0s 102us/sample - loss: 1771800412.9315 - val_loss: 2261193440.0877\n",
      "Epoch 31/100\n",
      "1095/1095 [==============================] - 0s 103us/sample - loss: 1710425294.6703 - val_loss: 2197193826.8932\n",
      "Epoch 32/100\n",
      "1095/1095 [==============================] - 0s 108us/sample - loss: 1679123878.5753 - val_loss: 2137405478.5753\n",
      "Epoch 33/100\n",
      "1095/1095 [==============================] - 0s 94us/sample - loss: 1623986668.4785 - val_loss: 2087611017.1178\n",
      "Epoch 34/100\n",
      "1095/1095 [==============================] - 0s 114us/sample - loss: 1583636491.8064 - val_loss: 2040707521.9288\n",
      "Epoch 35/100\n",
      "1095/1095 [==============================] - 0s 109us/sample - loss: 1548885867.0758 - val_loss: 1994047252.3397\n",
      "Epoch 36/100\n",
      "1095/1095 [==============================] - 0s 129us/sample - loss: 1509208924.1132 - val_loss: 1946349098.4329\n",
      "Epoch 37/100\n",
      "1095/1095 [==============================] - 0s 108us/sample - loss: 1476269532.9315 - val_loss: 1907427273.2932\n",
      "Epoch 38/100\n",
      "1095/1095 [==============================] - 0s 112us/sample - loss: 1444712564.6612 - val_loss: 1870078109.8082\n",
      "Epoch 39/100\n",
      "1095/1095 [==============================] - 0s 101us/sample - loss: 1417009552.7160 - val_loss: 1836929288.4164\n",
      "Epoch 40/100\n",
      "1095/1095 [==============================] - 0s 101us/sample - loss: 1388394292.0183 - val_loss: 1807796997.9616\n",
      "Epoch 41/100\n",
      "1095/1095 [==============================] - 0s 105us/sample - loss: 1356584906.3452 - val_loss: 1780009381.5233\n",
      "Epoch 42/100\n",
      "1095/1095 [==============================] - 0s 108us/sample - loss: 1333025543.3059 - val_loss: 1746815181.1507\n",
      "Epoch 43/100\n",
      "1095/1095 [==============================] - 0s 102us/sample - loss: 1304028367.2548 - val_loss: 1716833845.3041\n",
      "Epoch 44/100\n",
      "1095/1095 [==============================] - 0s 105us/sample - loss: 1282764350.6557 - val_loss: 1687789866.7836\n",
      "Epoch 45/100\n",
      "1095/1095 [==============================] - 0s 103us/sample - loss: 1257798627.2438 - val_loss: 1664048452.0329\n",
      "Epoch 46/100\n",
      "1095/1095 [==============================] - 0s 101us/sample - loss: 1237471723.9525 - val_loss: 1635451840.5260\n",
      "Epoch 47/100\n",
      "1095/1095 [==============================] - 0s 102us/sample - loss: 1217955891.7845 - val_loss: 1608215795.7260\n",
      "Epoch 48/100\n",
      "1095/1095 [==============================] - 0s 105us/sample - loss: 1198221882.6228 - val_loss: 1589618737.0959\n",
      "Epoch 49/100\n",
      "1095/1095 [==============================] - 0s 125us/sample - loss: 1175714914.6009 - val_loss: 1566199505.0082\n",
      "Epoch 50/100\n",
      "1095/1095 [==============================] - 0s 102us/sample - loss: 1160477606.5753 - val_loss: 1547010030.4658\n",
      "Epoch 51/100\n",
      "1095/1095 [==============================] - 0s 98us/sample - loss: 1142477015.0283 - val_loss: 1524561761.1397\n",
      "Epoch 52/100\n",
      "1095/1095 [==============================] - 0s 109us/sample - loss: 1121852297.6438 - val_loss: 1503397661.4575\n",
      "Epoch 53/100\n",
      "1095/1095 [==============================] - 0s 111us/sample - loss: 1105565173.9470 - val_loss: 1484825916.3178\n",
      "Epoch 54/100\n",
      "1095/1095 [==============================] - 0s 123us/sample - loss: 1087826683.7333 - val_loss: 1476796265.3808\n",
      "Epoch 55/100\n",
      "1095/1095 [==============================] - 0s 98us/sample - loss: 1075311366.4877 - val_loss: 1463906815.8247\n",
      "Epoch 56/100\n",
      "1095/1095 [==============================] - 0s 98us/sample - loss: 1064976326.2539 - val_loss: 1441233817.6000\n",
      "Epoch 57/100\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 1043253674.3160 - val_loss: 1430733044.0767\n",
      "Epoch 58/100\n",
      "1095/1095 [==============================] - 0s 100us/sample - loss: 1031422170.9151 - val_loss: 1412725642.6959\n",
      "Epoch 59/100\n",
      "1095/1095 [==============================] - 0s 96us/sample - loss: 1016228793.7461 - val_loss: 1397569182.3342\n",
      "Epoch 60/100\n",
      "1095/1095 [==============================] - 0s 98us/sample - loss: 1002977840.1023 - val_loss: 1386470278.1370\n",
      "Epoch 61/100\n",
      "1095/1095 [==============================] - 0s 115us/sample - loss: 990583551.0064 - val_loss: 1377338576.4822\n",
      "Epoch 62/100\n",
      "1095/1095 [==============================] - 0s 171us/sample - loss: 984064261.2603 - val_loss: 1370375265.6658\n",
      "Epoch 63/100\n",
      "1095/1095 [==============================] - 0s 136us/sample - loss: 965034002.0018 - val_loss: 1351605640.0658\n",
      "Epoch 64/100\n",
      "1095/1095 [==============================] - 0s 103us/sample - loss: 954583333.0849 - val_loss: 1339294252.5370\n",
      "Epoch 65/100\n",
      "1095/1095 [==============================] - 0s 106us/sample - loss: 943353557.2164 - val_loss: 1329264806.7507\n",
      "Epoch 66/100\n",
      "1095/1095 [==============================] - 0s 108us/sample - loss: 934664635.7333 - val_loss: 1324311622.1370\n",
      "Epoch 67/100\n",
      "1095/1095 [==============================] - 0s 104us/sample - loss: 925188077.3553 - val_loss: 1316275221.5671\n",
      "Epoch 68/100\n",
      "1095/1095 [==============================] - 0s 109us/sample - loss: 914010230.0932 - val_loss: 1305852330.9589\n",
      "Epoch 69/100\n",
      "1095/1095 [==============================] - 0s 125us/sample - loss: 902416944.8621 - val_loss: 1289275157.7425\n",
      "Epoch 70/100\n",
      "1095/1095 [==============================] - 0s 121us/sample - loss: 892234436.2667 - val_loss: 1284112039.6274\n",
      "Epoch 71/100\n",
      "1095/1095 [==============================] - 0s 132us/sample - loss: 884251298.5425 - val_loss: 1280125879.0575\n",
      "Epoch 72/100\n",
      "1095/1095 [==============================] - 0s 101us/sample - loss: 878301938.9078 - val_loss: 1266358164.8658\n",
      "Epoch 73/100\n",
      "1095/1095 [==============================] - 0s 113us/sample - loss: 866380266.9589 - val_loss: 1264130096.5699\n",
      "Epoch 74/100\n",
      "1095/1095 [==============================] - 0s 117us/sample - loss: 855241296.8329 - val_loss: 1258073346.8055\n",
      "Epoch 75/100\n",
      "1095/1095 [==============================] - 0s 106us/sample - loss: 849542754.7178 - val_loss: 1246014779.9671\n",
      "Epoch 76/100\n",
      "1095/1095 [==============================] - 0s 107us/sample - loss: 842598952.2703 - val_loss: 1251984745.7315\n",
      "Epoch 77/100\n",
      "1095/1095 [==============================] - 0s 113us/sample - loss: 842021084.1132 - val_loss: 1230491862.0932\n",
      "Epoch 78/100\n",
      "1095/1095 [==============================] - 0s 111us/sample - loss: 824051624.0365 - val_loss: 1230942060.1863\n",
      "Epoch 79/100\n",
      "1095/1095 [==============================] - 0s 121us/sample - loss: 817961167.0210 - val_loss: 1224610940.4932\n",
      "Epoch 80/100\n",
      "1095/1095 [==============================] - 0s 123us/sample - loss: 814162229.4210 - val_loss: 1226260191.5616\n",
      "Epoch 81/100\n",
      "1095/1095 [==============================] - 0s 107us/sample - loss: 802772112.5991 - val_loss: 1213383325.6329\n",
      "Epoch 82/100\n",
      "1095/1095 [==============================] - 0s 113us/sample - loss: 796243960.8694 - val_loss: 1205334415.0795\n",
      "Epoch 83/100\n",
      "1095/1095 [==============================] - 0s 105us/sample - loss: 788797825.2858 - val_loss: 1204468463.5178\n",
      "Epoch 84/100\n",
      "1095/1095 [==============================] - 0s 116us/sample - loss: 793971008.1169 - val_loss: 1193098521.4247\n",
      "Epoch 85/100\n",
      "1095/1095 [==============================] - 0s 130us/sample - loss: 780156217.3370 - val_loss: 1212480838.8384\n",
      "Epoch 86/100\n",
      "1095/1095 [==============================] - 0s 123us/sample - loss: 771481121.5781 - val_loss: 1189998101.9178\n",
      "Epoch 87/100\n",
      "1095/1095 [==============================] - 0s 136us/sample - loss: 765949982.0128 - val_loss: 1186354605.0630\n",
      "Epoch 88/100\n",
      "1095/1095 [==============================] - 0s 113us/sample - loss: 764969090.4548 - val_loss: 1177787158.7945\n",
      "Epoch 89/100\n",
      "1095/1095 [==============================] - 0s 103us/sample - loss: 754116886.0347 - val_loss: 1185342181.5233\n",
      "Epoch 90/100\n",
      "1095/1095 [==============================] - 0s 105us/sample - loss: 743404256.2046 - val_loss: 1171582712.1096\n",
      "Epoch 91/100\n",
      "1095/1095 [==============================] - 0s 103us/sample - loss: 740242121.3516 - val_loss: 1166365216.4384\n",
      "Epoch 92/100\n",
      "1095/1095 [==============================] - 0s 109us/sample - loss: 740642149.6110 - val_loss: 1172731355.7041\n",
      "Epoch 93/100\n",
      "1095/1095 [==============================] - 0s 103us/sample - loss: 729151079.5982 - val_loss: 1153881714.4986\n",
      "Epoch 94/100\n",
      "1095/1095 [==============================] - 0s 106us/sample - loss: 729388111.3717 - val_loss: 1165097452.3616\n",
      "Epoch 95/100\n",
      "1095/1095 [==============================] - 0s 103us/sample - loss: 717037264.2776 - val_loss: 1153182391.2329\n",
      "Epoch 96/100\n",
      "1095/1095 [==============================] - 0s 104us/sample - loss: 712273136.8621 - val_loss: 1151420386.7178\n",
      "Epoch 97/100\n",
      "1095/1095 [==============================] - 0s 119us/sample - loss: 710456128.2338 - val_loss: 1154538142.6849\n",
      "Epoch 98/100\n",
      "1095/1095 [==============================] - 0s 103us/sample - loss: 702104012.1863 - val_loss: 1150111342.6411\n",
      "Epoch 99/100\n",
      "1095/1095 [==============================] - 0s 103us/sample - loss: 696783687.2475 - val_loss: 1142926954.2575\n",
      "Epoch 100/100\n",
      "1095/1095 [==============================] - 0s 102us/sample - loss: 692434308.7927 - val_loss: 1142733685.3041\n",
      "RMSE: 0.2004\n",
      "モデルの作成終了: 2020-02-16 09:28:38.568065\n"
     ]
    }
   ],
   "source": [
    "printTime('モデルの作成開始')\n",
    "\n",
    "# 学習データを学習データとバリデーションデータに分ける\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "tr_idx, va_idx = list(kf.split(train_x))[0]\n",
    "tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "\n",
    "\n",
    "# tensorflowの警告抑制\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# データのスケーリング\n",
    "scaler = StandardScaler()\n",
    "tr_x = scaler.fit_transform(tr_x)\n",
    "va_x = scaler.transform(va_x)\n",
    "test_x = scaler.transform(test_x)\n",
    "\n",
    "# pandas.core.series.Series型のままだと学習時にエラーするので、ndarrayに変換\n",
    "tr_y = np.asarray(tr_y)\n",
    "va_y = np.asarray(va_y)\n",
    "\n",
    "# ニューラルネットワークモデルの生成\n",
    "# モデルの構成は\n",
    "# 入力(13次元)-1000次元-800次元-100次元-予測値(1次元)\n",
    "# Sequential()というのは入力から枝分かれせずに書けるモデルのクラス\n",
    "# Dense()は全結合層\n",
    "# activation は活性化関数，ここではReLUを用いている\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dense(800, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# モデルをコンパイル\n",
    "# コンパイルすることで逆伝搬などが準備される\n",
    "# 最適化関数として Adam を指定\n",
    "# 誤差関数には平均2乗誤差を指定\n",
    "\n",
    "\n",
    "model.compile(Adam(lr=1e-3), loss=\"mean_squared_error\")\n",
    "\n",
    "\n",
    "# トレーニングデータで学習し，テストデータで評価\n",
    "\n",
    "# batch_size: ミニバッチのデータ数\n",
    "# epochs: 全部のデータについて処理する回数 1epoch = 1周\n",
    "# verbose: 表示の形式，0だと何も表示されない\n",
    "# validation_data: 評価用データ（ここではハイパーパラメータの調整をしないので\n",
    "#   テストデータをそのまま用いている）\n",
    "\n",
    "history = model.fit(tr_x,\n",
    "                    tr_y,\n",
    "                    batch_size=128,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=(va_x, va_y))\n",
    "\n",
    "# バリデーションデータでのスコアの確認\n",
    "va_pred = model.predict(va_x)\n",
    "\n",
    "# バリデーションデータでのスコア(真の値の対数と予測値の対数の二乗平均平方根誤差 (RMSE))を計算する\n",
    "rmse = np.sqrt(mean_squared_error(np.log(va_y), np.log(va_pred)))\n",
    "\n",
    "print(f'RMSE: {rmse:.4f}')\n",
    "\n",
    "# 予測\n",
    "pred = model.predict(test_x)\n",
    "\n",
    "pred = pd.DataFrame(pred)[0]\n",
    "\n",
    "# 提出用ファイルの作成\n",
    "submission = pd.DataFrame({'Id': test['Id'], 'SalePrice': pred})\n",
    "submission.to_csv('/kaggle/output/submission_first.csv', index=False)\n",
    "\n",
    "printTime('モデルの作成終了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
